# ðŸ¤– Interpretable Chatbot with Confidence Tooltips

A Streamlit web application that provides an interpretable chatbot interface with token-level confidence analysis and interactive tooltips.

## âœ¨ Features

- **Interactive Chat Interface**: Simple and intuitive chatbot UI
- **Token-Level Confidence Analysis**: See confidence scores for each token in the response
- **Hover Tooltips**: Hover over any token to see its individual confidence percentage
- **Overall Confidence Display**: Color-coded confidence labels at the top of each response
- **Chat History**: View all previous conversations with confidence analysis
- **Real-time Analysis**: Uses OpenAI's `gpt-3.5-turbo-instruct` model with `logprobs` parameter

## ðŸŽ¨ Confidence Color Coding

- ðŸŸ¢ **Green (â‰¥90%)**: High confidence
- ðŸŸ¡ **Yellow (75-89%)**: Good confidence  
- ðŸŸ  **Orange (60-74%)**: Moderate confidence
- ðŸ”´ **Red (<60%)**: Low confidence

## ðŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Set Up OpenAI API Key

Create a `.env` file in the project root:

```bash
cp env_example.txt .env
```

Then edit `.env` and add your OpenAI API key:

```
OPENAI_API_KEY=your_actual_api_key_here
```

**Get your API key from:** [OpenAI Platform](https://platform.openai.com/api-keys)

### 3. Run the Application

```bash
streamlit run streamlit_app.py
```

The app will open in your browser at `http://localhost:8501`

## ðŸš€ Deployment

For secure deployment options, see [DEPLOYMENT.md](DEPLOYMENT.md) for detailed instructions on:

- **Streamlit Cloud** (Recommended - easiest)
- **Heroku**
- **Docker**
- **Railway**

All deployment methods keep your API keys secure using environment variables or secrets management.

## ðŸ“– How to Use

1. **Enter your OpenAI API key** in the sidebar
2. **Type a question** in the input field
3. **Click Send** to get a response with confidence analysis
4. **Hover over tokens** in the response to see individual confidence scores
5. **View overall confidence** with the colored label at the top

## ðŸ”§ Technical Details

### Confidence Calculation

The app calculates confidence using the following process:

1. **Token Analysis**: Uses OpenAI's `logprobs` parameter to get probability distributions for each token
2. **Confidence Score**: `confidence = exp(logprob) * 100`
3. **Overall Confidence**: Average of all token confidences
4. **Display**: Rounded to one decimal place as percentage

### Token Tooltips

Each token is rendered with:
- **Hover tooltip**: Shows individual confidence percentage
- **Visual indicator**: Dotted underline to suggest interactivity
- **Cursor change**: Help cursor on hover

### API Configuration

- **Model**: `gpt-3.5-turbo-instruct`
- **Logprobs**: 5 (returns top 5 probability distributions per token)
- **Max Tokens**: 150
- **Temperature**: 0.7

## ðŸ“ Project Structure

```
Interp/
â”œâ”€â”€ app.py              # Main Streamlit application
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ env_example.txt     # Example environment configuration
â””â”€â”€ README.md          # This file
```

## ðŸ› ï¸ Dependencies

- **Streamlit**: Web application framework
- **OpenAI**: API client for GPT models (v1.0.0+)
- **python-dotenv**: Environment variable management

## ðŸ”’ Security Notes

- API keys are stored securely in environment variables
- HTML content is properly escaped to prevent XSS attacks
- No sensitive data is logged or stored

## ðŸ¤ Contributing

Feel free to submit issues and enhancement requests!

## ðŸ“„ License

This project is open source and available under the MIT License. 

## ðŸ‘¤ Made by

**Samuel Robson**  
Product-minded strategist and AI prototyper  
ðŸŽ“ MIMS @ UC Berkeley  
ðŸ› ï¸ Interpretability Â· Tangible Interfaces Â· Human-Centered AI

[GitHub](https://github.com/samuelrobson4) Â· [LinkedIn](https://www.linkedin.com/in/samuelrobson1/)
